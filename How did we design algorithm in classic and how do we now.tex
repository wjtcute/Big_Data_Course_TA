\documentclass{beamer}

% \usepackage{beamerthemesplit} // Activate for custom appearance
\usetheme{Warsaw} 

\usepackage{graphicx}
%\usepackgae{amsmath}
\usepackage{amsthm}
\usepackage{amsmath,bm}
\usepackage{amssymb}

\title{How did we meet data and design algorithm in classic computer science and how do we now?}

\begin{document}

\frame{
\maketitle
}

\frame{
\frametitle{How did we meet data and design algorithm in classic computer science?}
\begin{enumerate}
\item Sort
\item Matching
\item Shortest Path
\item SAT
\end{enumerate}
No matter how the input data varies, we can always guarantee that our algorithm achieves our objective precisely. 
}

\frame{
\frametitle{How do we meet data and design algorithm now?}
\centering{Using machine learning as an example}
}

\frame{
\frametitle{How do we meet data and design algorithm now?}
For example, a classification problem:
\begin{itemize}
\item Given the features of some new customers of a bank, can we judge whether they will buy a financial product within a year, based on the experience.
\item The experience means the data of the features of old customers and whether they bought any financial product during the first year they registered as a customer of the bank.
\end{itemize}

\begin{table}[!h]
\begin{tiny}
\centering
\caption{A toy example of data}
\begin{tabular}{|c|c|c|c|} 
\hline
Feature \#1 & Feature \#2 & Feature \#3 & Tag\\
\hline
Age & Income & Also a customer of another bank & Brought or Not\\
\hline
28 & 10000 & 0 (No) & 0 (No)\\
\hline
$\cdot\cdot\cdot$ & $\cdot\cdot\cdot $& $\cdot\cdot\cdot$ & $\cdot\cdot\cdot$\\
\hline
40 & 30000 & 1 (Yes) & 1 (Yes)\\
\hline
\end{tabular} 
\end{tiny}
\end{table}
}

\frame{
\frametitle{How do we meet data and design algorithm now?}
\begin{itemize}
\item \textbf{Problem}:  In abstract level, we have a couple of samples (data) generated from the same data generator. Each sample consists of a feature vector $\vec{x}_i$ and a tag $y_i\in\{0,1\}$. If there are some other samples generated by the data generator, can we predict the tags of these samples as precisely as possible by just knowing their feature vectors.
\item \textbf{Objective}: What we really want to know is the map from the feature vector to the tag implied by the data generator.
\end{itemize}
}

\frame{
\frametitle{Algorithm Design}
To design a corresponding algorithm, we convert the objective to one of the two followings:
\begin{enumerate}
\item We want to find a map without lose of generalizability to best fit the existing samples, based on the belief that the map which best fits the existing sample will best act on the new generated data.
\item We want to find a map which will generate the existing data with highest probability, based on the assumption that the data generator follows certain type of stochastic mapping mechanism to generate the data. 
\end{enumerate}
\centering{The nature is an optimization problem!}
}

\frame{
\frametitle{Logistic Classification Algorithm}
Suppose the data is generated (or the relation is) in the function form $$y_i=h(\vec{x}_i)=\frac{1}{1+e^{-{\vec\theta}^{\text{T}}\vec{x}_i}}$$ 
where $\vec\theta$ are free variables to be determined. We aim to maximize the generating probability of the existing data $$l(\vec\theta) = \Pi_i h(\vec{x}_i)^{y_i}(1-h(\vec{x}_i))^{1-y_i}$$
This can be done by using classic optimization algorithm, the gradient descent.
\begin{enumerate}
\item Set $\vec \theta$ to arbitrary values
\item Update $\vec \theta = \vec \theta + \alpha \frac{dl}{d\vec{\theta}}$ till converge, \\ or more commonly, update one sample by one sample, $\vec \theta = \vec \theta + \alpha (y_i-h(\vec{x}_i))\vec{x}$.
\end{enumerate}
}

\frame{
\frametitle{Logistic Classification}
In sum,
\begin{itemize}
\item \textbf{Input}: labeled data samples as points in high dimension space with a classification tag 0 or 1
\item \textbf{Objective}: find a linear function embedded in a logistic function that can predict the unlabeled data samples
\item \textbf{Output}: the function parameters
\end{itemize}
}

\frame{
\frametitle{How do we meet data and design algorithm now?}
\begin{enumerate}
\item Supervised learning:
\begin{itemize}
\item Support Vector Machine (SVM)
\item Neural networks (NN)
\end{itemize}
\item Unsupervised learning:
\begin{itemize}
\item Principal Component Analysis (PCA)
\item K-means
\end{itemize}
\item Reinforcement learning

\end{enumerate}
}

\frame{
\frametitle{SVM}
\begin{itemize}
\item \textbf{Input}: labelled data samples as points in a high dimension space
\item \textbf{Objective}: find out a hyperplane in a high dimension  that best separates samples with different tags
\item \textbf{Output}: a hyperplane that separate two types of samples while maximizes the sum of the minimum distance to the hyperplane of samples of each  type.
\end{itemize}
}

\frame{
\frametitle{Neural Networks}
\begin{itemize}
\item \textbf{Input}: labelled data samples as points in a high dimension space
\item \textbf{Objective}: neural networks can mimic arbitrary function. Find a function without lose of generalizability that best fits the relation of existing data
\item \textbf{Output}: a function in the form of a neural network that maximizes the fitness (generating probability) of the given data while keeps the  generalizability
\end{itemize}
}


\frame{
\frametitle{PCA}
\begin{itemize}
\item \textbf{Input}: data samples as points in a high dimension space
\item \textbf{Objective}: find out a few orthogonal directions such that the distances of these points on these directions are maximized
\item \textbf{Output}: a couple of orthogonal directions
\end{itemize}
}

\frame{
\frametitle{K-means}
\begin{itemize}
\item \textbf{Input}: data samples as points in a high dimension space
\item \textbf{Objective}: identify the similarity of the data and which pair of samples is more similar than another pair. The similarity is in a relatively vague meaning.
\item \textbf{Output}: a couple of center points in a high dimension space that the sum of distance of each given point to the nearest center is maximized
\end{itemize}
}


\frame{
\frametitle{Reinforcement Learning}
\begin{itemize}
\item \textbf{Input}: an environment which consists of an action space, an state space and a state transition function and a reward function on states. 
\item \textbf{Objective}: find an action generator that can generate according to state transition history a sequence of actions that maximizes the final reward. 
\end{itemize}
}
\end{document}
%\section[Outline]{}
%\frame{\tableofcontents}

%\section{Introduction}
%\subsection{Overview of the Beamer Class}
%\frame
%{
%  \frametitle{Features of the Beamer Class}

%  \begin{itemize}
%  \item<1-> Normal LaTeX class.
%  \item<2-> Easy overlays.
%  \item<3-> No external programs needed.      
%  \end{itemize}
%}
